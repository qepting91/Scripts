{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# Scripts For Overt Operator\n# To run scripts save them as a .py file\n# Then in command line run the command Python \"file\".py",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# APIS Necessary for Certain Scripts\n\n## Shodan API key:\n### To obtain an API key for Shodan, you need to sign up for a free or paid account on their website at https://www.shodan.io/. Once you have created an account, you can access your API key by navigating to your account settings and clicking on the \"API\" tab.\n\n## Hunter.io API key:\n### To obtain an API key for Hunter.io, you need to sign up for a free or paid account on their website at https://hunter.io/. Once you have created an account, you can access your API key by navigating to your account settings and clicking on the \"API\" tab.\n\n## Have I Been Pwned API key:\n### To obtain an API key for Have I Been Pwned, you need to sign up for a free account on their website at https://haveibeenpwned.com/API/Key. Once you have created an account, you can access your API key by navigating to the API page and clicking on the \"Generate new API key\" button.\n\n## VirusTotal API key:\n###To obtain an API key for VirusTotal, you need to sign up for a free or paid account on their website at https://www.virustotal.com/. Once you have created an account, you can access your API key by navigating to your profile page and clicking on the \"API key\" tab. Note that the free version of the VirusTotal API has limited functionality and is subject to usage restrictions.\n\n## Twitter API key:\n### To obtain an API key for Twitter, you need to apply for a developer account on their website at https://developer.twitter.com/en/apply-for-access. Once you have been approved for a developer account, you can create a new app and generate API keys for that app. Note that the process of obtaining a developer account can take several days and requires you to provide detailed information about your intended use of the API. Additionally, some Twitter API endpoints may require additional permissions beyond what is granted by default to developer accounts.\n\n## Google Maps API key:\n### To obtain an API key for Google Maps, you need to create a project on the Google Cloud Console at https://console.cloud.google.com/. Once you have created a project, you can enable the Google Maps JavaScript API and generate an API key for that API. Note that usage of the Google Maps API may be subject to usage restrictions and billing based on your usage levels.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "## Website Scraper\n\nimport requests\n\nurl = 'http://example.com'\nr = requests.get(url)\n\nwith open('output.html', 'w') as f:\n    f.write(r.content)\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# IP address geolocation\n\nimport requests\n\nip_address = '8.8.8.8'\n\nurl = f'https://ipinfo.io/{ip_address}/json'\n\nr = requests.get(url)\n\nprint(r.json())\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# DNS Lookup\n\nimport dns.resolver\n\ndomain_name = 'example.com'\n\nanswers = dns.resolver.query(domain_name)\n\nfor rdata in answers:\n    print(rdata)\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Whois Lookup\n\nimport whois\n\ndef lookup_whois(domain):\n    try:\n        w = whois.whois(domain)\n        return {\n            'domain_name': w.domain_name,\n            'registrar': w.registrar,\n            'creation_date': w.creation_date,\n            'expiration_date': w.expiration_date,\n            'updated_date': w.updated_date,\n            'name_servers': w.name_servers,\n            'status': w.status\n\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Email Address Verification\n\nimport re\nimport smtplib\n\ndef validate_email(email):\n    if not re.match(r\"[^@]+@[^@]+\\.[^@]+\", email):\n        return False\n    else:\n        try:\n            server = smtplib.SMTP('example.com', 25)\n            server.connect()\n            server.helo()\n            server.mail('me@example.com')\n            code, message = server.rcpt(str(email))\n            server.quit()\n            if code == 250:\n                return True\n            else:\n                return False\n        except Exception as e:\n            return False\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Email Header Analysis\n\nimport email\nfrom email.header import decode_header\n\ndef analyze_email_headers(email_message):\n    headers = email_message._headers\n    for h in headers:\n        name = h[0]\n        value = h[1]\n        decoded_value = decode_header(value)[0][0]\n        print(f'{name}: {decoded_value}')\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# IP geolocation \n\nimport requests\n\ndef geolocate_ip(ip_address):\n    try:\n        url = f'https://ipapi.co/{ip_address}/json/'\n        response = requests.get(url)\n        data = response.json()\n        return {'city': data['city'], 'region': data['region'], 'country': data['country_name']}\n    except Exception as e:\n        return None\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Password Strength Checker\n\nimport re\n\ndef check_password_strength(password):\n    # Minimum 8 characters, at least 1 uppercase letter, 1 lowercase letter, 1 number, and 1 special character\n    pattern = r'^(?=.*[a-z])(?=.*[A-Z])(?=.*\\d)(?=.*[@$!%*?&])[A-Za-z\\d@$!%*?&]{8,}$'\n    if re.match(pattern, password):\n        return True\n    else:\n        return False\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Hash Generator\n\nimport hashlib\n\ndef generate_hash(string, algorithm='sha256'):\n    if algorithm == 'sha256':\n        return hashlib.sha256(string.encode()).hexdigest()\n    elif algorithm == 'md5':\n        return hashlib.md5(string.encode()).hexdigest()\n    else:\n        return None\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# URL Decoding\n\nimport urllib.parse\n\ndef decode_url(url):\n    return urllib.parse.unquote(url)\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Email address obfuscation\n\ndef obfuscate_email(email):\n    username, domain = email.split('@')\n    obfuscated_username = f'{username[:2]}***{username[-2:]}'\n    return f'{obfuscated_username}@{domain}'\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Port Scanner\n\nimport socket\n\ndef scan_ports(ip_address, start_port, end_port):\n    open_ports = []\n    for port in range(start_port, end_port+1):\n        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n        sock.settimeout(1)\n        result = sock.connect_ex((ip_address, port))\n        if result == 0:\n            open_ports.append(port)\n        sock.close()\n    return open_ports\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# File Type Detection\n\nimport magic\n\ndef detect_file_type(file_path):\n    with magic.Magic() as m:\n        return m.from_file(file_path)\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# PDF metadata extraction\n\nimport PyPDF2\n\ndef extract_pdf_metadata(file_path):\n    with open(file_path, 'rb') as f:\n        pdf_reader = PyPDF2.PdfFileReader(f)\n        info = pdf_reader.getDocumentInfo()\n        metadata = {}\n        for k, v in info.items():\n            metadata[k] = v\n        return metadata\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Image metadata extraction\n\nfrom PIL import Image\n\ndef extract_image_metadata(file_path):\n    with Image.open(file_path) as img:\n        return {k: v for k, v in img.info.items()}\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Test File Keyword Search\n\ndef search_text_file(file_path, keyword):\n    with open(file_path, 'r') as f:\n        for line in f:\n            if keyword in line:\n                return True\n        return False\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Webcam Snapshot\n\nimport cv2\n\ndef take_webcam_snapshot(file_path):\n    cap = cv2.VideoCapture(0)\n    ret, frame = cap.read()\n    cv2.imwrite(file_path, frame)\n    cap.release()\n\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Dark Web Crawler\n#This script crawls the Tor network to identify hidden services that may be related to criminal activities. It can be used to identify potential threats or to track the activities of specific threat actors.\n\nimport requests\nimport json\nimport stem\nimport stem.control\nfrom stem import Signal\nfrom stem.util import term\n\ndef get_hidden_services():\n    # Create Tor control connection\n    with stem.control.Controller.from_port() as controller:\n        controller.authenticate()\n\n        # Get new Tor identity\n        controller.signal(Signal.NEWNYM)\n\n    # Use new Tor identity to make request\n    session = requests.session()\n    session.proxies = {\n        'http': 'socks5h://localhost:9050',\n        'https': 'socks5h://localhost:9050'\n    }\n\n    # Scrape hidden services from Tor network\n    hidden_services = []\n    for i in range(1, 10):\n        url = 'http://{}.onion'.format(str(i))\n        try:\n            response = session.get(url, timeout=5)\n            if response.status_code == 200:\n                hidden_services.append(url)\n        except:\n            pass\n\n    return hidden_services\n\nif __name__ == '__main__':\n    hidden_services = get_hidden_services()\n    print(hidden_services)\n\n#This will execute the get_hidden_services() function and print the list of scraped hidden services to the console. Note that you need to have Tor installed and running on your system with the default configuration, as well as the Requests and Stem libraries installed in your Python environment.",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Domain Reputation Checker\n#This script checks the reputation of a domain using a variety of sources, including blacklists and SSL certificate information. It can be used to identify potentially malicious domains or to assess the security posture of a specific organization.\n\nimport requests\nimport json\nimport ssl\nimport socket\nimport dns.resolver\n\ndef check_domain_reputation(domain):\n    # Check blacklists\n    url = 'https://www.virustotal.com/vtapi/v2/domain/report'\n    params = {'apikey': 'your_api_key', 'domain': domain}\n    response = requests.get(url, params=params)\n    data = json.loads(response.text)\n\n    if data['response_code'] == 1:\n        for scanner in data['scans']:\n            if data['scans'][scanner]['detected']:\n                print('Domain is blacklisted by ' + scanner)\n\n    # Check SSL certificate\n    context = ssl.create_default_context()\n    with socket.create_connection((domain, 443)) as sock:\n        with context.wrap_socket(sock, server_hostname=domain) as sslsock:\n            cert = sslsock.getpeercert()\n            issuer = dict(x[0] for x in cert['issuer'])\n            subject = dict(x[0] for x in cert['subject'])\n            print('Issuer: ' + issuer['organizationName'])\n            print('Subject: ' + subject['commonName'])\n\n    # Check DNS records\n    resolver = dns.resolver.Resolver()\n    resolver.nameservers = ['8.8.8.8', '8.8.4.\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Email Scraper\n#This script uses the IMAP protocol to scrape emails from a specific email account. It can be used to identify patterns in phishing attacks or to track conversations between threat actors.\n\n\n\nimport imaplib\nimport email\n\ndef get_emails(server, email_address, password, folder_name):\n    mail = imaplib.IMAP4_SSL(server)\n    mail.login(email_address, password)\n    mail.select(folder_name)\n\n    _, search_data = mail.search(None, 'ALL')\n    email_ids = search_data[0].split()\n\n    emails = []\n\n    for email_id in email_ids:\n        _, data = mail.fetch(email_id, '(RFC822)')\n        email_message = email.message_from_bytes(data[0][1])\n        parsed_email = {}\n        parsed_email['from'] = email_message['From']\n        parsed_email['subject'] = email_message['Subject']\n        parsed_email['body'] = email_message.get_payload(decode=True).decode()\n        emails.append(parsed_email)\n\n    mail.close()\n    mail.logout()\n\n    return emails\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Twitter Scraper\n#This script uses the Twitter API to scrape tweets from public accounts. It can be used to monitor conversations related to a particular topic or to identify influencers in a specific industry. The data can be used to build a sentiment analysis model or to identify potential threats or opportunities.\n\nimport tweepy\n\ndef get_tweets(query, count):\n    consumer_key = 'your_consumer_key'\n    consumer_secret = 'your_consumer_secret'\n    access_token = 'your_access_token'\n    access_token_secret = 'your_access_token_secret'\n\n    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n    auth.set_access_token(access_token, access_token_secret)\n\n    api = tweepy.API(auth)\n\n    tweets = []\n    fetched_tweets = api.search(q=query, count=count)\n\n    for tweet in fetched_tweets:\n        parsed_tweet = {}\n        parsed_tweet['text'] = tweet.text\n        parsed_tweet['created_at'] = tweet.created_at.strftime(\"%Y-%m-%d %H:%M:%S\")\n        tweets.append(parsed_tweet)\n\n    return tweets\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "# Nmap and Recon-NG merger\n#Import the required libraries and modules, such as subprocess and argparse.\n\n#Define the input parameters for the script, such as the target IP or domain, and the output directory for the scan results.\n\n#Define functions to run the reconnaissance tools, such as Nmap and Recon-ng, on the target.\n\n#Create a directory to store the results of the reconnaissance scans.\n\n#Run the Nmap scan on the target and save the results to a file in the output directory.\n\n#Run the Recon-ng scan on the target and save the results to a file in the output directory.\n\n#Merge the results from both scans into a single file.\n\n#Display the results of the scans on the screen for the user to review.\n\n#Ask the user if they want to perform additional scans or exit the script.\n\n#If the user chooses to perform additional scans, prompt them for the target IP or domain and repeat the scan process.\n\n#If the user chooses to exit the script, display a message thanking them for using the script and exit.\n\nimport os\nimport subprocess\nimport argparse\n\n# Define input arguments\nparser = argparse.ArgumentParser()\nparser.add_argument('target', help='Target IP or domain')\nparser.add_argument('output_dir', help='Output directory for scan results')\nargs = parser.parse_args()\n\n# Define functions to run Nmap and Recon-ng scans\ndef run_nmap_scan(target, output_file):\n    nmap_cmd = f'nmap -sS -sV -O -oN {output_file} {target}'\n    subprocess.run(nmap_cmd, shell=True)\n\ndef run_recon_ng_scan(target, output_file):\n    recon_ng_cmd = f'recon-ng -r {target} -m discovery -o {output_file}'\n    subprocess.run(recon_ng_cmd, shell=True)\n\n# Create output directory for scan results\nif not os.path.exists(args.output_dir):\n    os.makedirs(args.output_dir)\n\n# Run Nmap scan on target and save results to file\nnmap_output_file = os.path.join(args.output_dir, 'nmap_scan.txt')\nrun_nmap_scan(args.target, nmap_output_file)\n\n# Run Recon-ng scan on target and save results to file\nrecon_ng_output_file = os.path.join(args.output_dir, 'recon_ng_scan.txt')\nrun_recon_ng_scan(args.target, recon_ng_output_file)\n\n# Merge results from both scans into a single file\nmerged_output_file = os.path.join(args.output_dir, 'merged_scan_results.txt')\nwith open(merged_output_file, 'w') as outfile:\n    with open(nmap_output_file) as infile1:\n        outfile.write(infile1.read())\n    with open(recon_ng_output_file) as infile2:\n        outfile.write(infile2.read())\n\n# Display results on screen for user to review\nwith open(merged_output_file) as results_file:\n    print(results_file.read())\n\n# Prompt user to perform additional scans or exit script\nwhile True:\n    choice = input('Do you want to perform additional scans? (Y/N): ')\n    if choice.upper() == 'Y':\n        target = input('Enter target IP or domain: ')\n        nmap_output_file = os.path.join(args.output_dir, 'nmap_scan.txt')\n        run_nmap_scan(target, nmap_output_file)\n\n        recon_ng_output_file = os.path.join(args.output_dir, 'recon_ng_scan.txt')\n        run_recon_ng_scan(target, recon_ng_output_file)\n\n        merged_output_file = os.path.join(args.output_dir, 'merged_scan_results.txt')\n        with open(merged_output_file, 'a') as outfile:\n            with open(nmap_output_file) as infile1:\n                outfile.write(infile1.read())\n            with open(recon_ng_output_file) as infile2:\n                outfile.write(infile2.read())\n\n        with open(merged_output_file) as results_file:\n            print(results_file.read())\n\n    elif choice.upper() == 'N':\n        print('Thank you for using the script.')\n        break\n\n    else:\n        print('Invalid choice. Please enter Y or N.')\n        \n# the script, save it as a .py file and run it from the command line with the following command:\n    \n    python open_source_intelligence.py <target_ip_or_domain> <output_directory>\n\n#Replace <target_ip_or_domain> with the IP address or domain you want to scan and <output_directory> with the directory where you want to save the scan results.\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}